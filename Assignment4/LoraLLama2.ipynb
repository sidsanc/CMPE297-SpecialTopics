{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBL37VivipYiWNJbLd65Lr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sidsanc/CMPE297-SpecialTopics/blob/main/Assignment4/LoraLLama2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "zjBCw89KaBSy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v92gbq4NYeZl"
      },
      "outputs": [],
      "source": [
        "!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.4.7"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3EkqTHmeGxY",
        "outputId": "3611d806-fd7b-4b21-c423-7e5275290827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
        "from peft import LoraConfig, PeftModel\n",
        "from trl import SFTTrainer\n",
        "import re\n",
        "from transformers import TrainingArguments"
      ],
      "metadata": {
        "id": "sHVimObwRCeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset from the HuggingFace Hub\n",
        "rd_ds = load_dataset(\"xiyuez/red-dot-design-award-product-description\")\n",
        "\n",
        "rd_df = pd.DataFrame(rd_ds['train'])\n",
        "rd_df['instruction'] = 'Create a detailed description for the following product: ' + rd_df['product'] + ', belonging to category: ' + rd_df['category']\n",
        "rd_df = rd_df[['instruction', 'description']]\n",
        "\n",
        "rd_df_sample = rd_df.sample(n=1000, random_state=42)\n",
        "\n",
        "# Define template\n",
        "template = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "\n",
        "{}\n",
        "\n",
        "### Response:\\n\"\"\"\n",
        "\n",
        "\n",
        "rd_df['prompt'] = rd_df[\"instruction\"].apply(lambda x: template.format(x))\n",
        "rd_df_sample['prompt'] = rd_df_sample[\"instruction\"].apply(lambda x: template.format(x))\n",
        "\n",
        "rd_df_sample.rename(columns={'description': 'response'}, inplace=True)\n",
        "rd_df_sample['text'] = rd_df_sample[\"prompt\"] + rd_df_sample[\"response\"]\n",
        "rd_df_sample['response'] = rd_df_sample['response'] + \"\\n### End\"\n",
        "\n",
        "rd_df_sample = rd_df_sample[['prompt', 'response']]\n",
        "\n",
        "rd_df['text'] = rd_df[\"prompt\"] + rd_df[\"description\"]\n",
        "\n",
        "rd_df.drop(columns=['prompt', 'description'], inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldcUHn9GYrbC",
        "outputId": "6a95715d-8dd1-482e-b932-7dd0c089ba11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-a94e66e45069>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  rd_df['prompt'] = rd_df[\"instruction\"].apply(lambda x: template.format(x))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = 'openlm-research/open_llama_3b_v2'\n",
        "tokenizer = LlamaTokenizer.from_pretrained(model_path)\n",
        "model = LlamaForCausalLM.from_pretrained(\n",
        "model_path, load_in_8bit=True, device_map='auto',\n",
        ")\n",
        "\n",
        "#Pass in a prompt and infer with the model\n",
        "prompt = 'Q: Create a detailed description for the following product: Corelogic Smooth Mouse, belonging to category: Optical Mouse\\nA:'\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "\n",
        "generation_output = model.generate(\n",
        "input_ids=input_ids, max_new_tokens=128\n",
        ")\n",
        "\n",
        "print(tokenizer.decode(generation_output[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537,
          "referenced_widgets": [
            "f9feb3d96db04c6ca0923588093276c6",
            "65f685bdc90248029c0830b46256302a",
            "89751ec0d0144787873b3294734dac8b",
            "4b466232260f4c699ffc82d48d3b2686",
            "304ac576963f4b5a9b06907b9910e5d2",
            "fa497d416bd845e7825351d309417cb5",
            "eabcbb1071be4c3589575342b35e5b76",
            "9a68b1b851b14b1f9580c686cfe89046",
            "7f50962a953b4efb8652ac178d61d919",
            "d01358adedf5452d9ff6b3627844df34",
            "f029d4cef5084effab1b9a42fc5200fc",
            "bca62cf53ca542f7a95b569b68183361",
            "de2fd02809c542248e9a519759f9111a",
            "243398bff59d4344bbd897c04118cadb",
            "43a1bbb3cca84d08a7a16c7bbb7901d3",
            "f7c5eedc1e15490784adbcfe11b298ad",
            "445425085b3143438f4e2659ecf4a66c",
            "f0c47fcf6e2c46d6a9539ea236f0d0d6",
            "92d8ecb758b947c5b100692e4a6f3e2b",
            "9ea4800b35c34d86b1a361ff8c8e678e",
            "022452170731444184f91476fd9db01c",
            "2c366624e7974327889dc31905962149",
            "e8135648785d4766adb88a7fae7eb2da",
            "72ec3c9d4e294564a8950eed821888ef",
            "23d3603c60c0417b9d57d6cc31fce856",
            "19d5077f7957413e8b2b8874a6a9dedf",
            "7483d1d13d6749a88dc4ae6ec246062c",
            "cf43e61a973b4b9cada104459a778a3c",
            "b083750e4b7a4500bd376fae32415f92",
            "b1f07227d3ec4abe9a7991d962a3880c",
            "9b9612291e004248be5e188115340622",
            "6dcf4ebdaa984605b9f337df691ce9e6",
            "da7905054223490e9cef113b88927125",
            "e6ac5609a7954fdcbb35fd74cd796d90",
            "a9f1119e7d2d44e9a9dd92b62d7ded70",
            "8f2b268f449c418781cdeb9645c94847",
            "9490d88b19d34aabb0fd009bbbc5e988",
            "dc6fd74a2d4b43329a3d24035d9e2f60",
            "3310fd543eae4535afe1d90a44166890",
            "beb3a9f3103041ed802409fd934ebdb6",
            "1a3f175850744eb09596a179a71da825",
            "690f722ed9be4bec9f3b512c92e351b3",
            "253eaf7c5cd7487ca1b1f3968aef3593",
            "d856e75cd1494cffbfa968223763c9c5",
            "4e121e8d521b4ed99313532918af18c4",
            "a1008b298bd64fb1a85c70473667dffa",
            "2f7edd3819f245458daccdb53edb9667",
            "2b471638f241438dae91795f085e7e91",
            "cfbc842ec02446a28438fc450afdcaf9",
            "54e7a36909bb4436b927617a98bdb1cc",
            "40ec6da2ad7a4ce790dc762786c162fe",
            "6422bb629d224d3db87774ad93e4fdc2",
            "ec03a5f82fed4a319c38916cdc1d7263",
            "a6ee0533a06048af944a862797f30170",
            "0a256afc47aa45ac9a3d63ab00161926",
            "d78f044db8fb44f8a374af4185ecb9ba",
            "1eb21221a12a45d9908af065f5141e30",
            "0eea3e96500640e0b65299990ec02102",
            "03262f89f1a24e7aac61f1fd900f9e25",
            "0dd8a0a345cb4d41a7f09b8f57d58333",
            "40bc53479d494845949d9e60752cfb34",
            "94c19321dcc24969bc2515f40ea112ce",
            "ae34123490be410b80556771cb541c4f",
            "40daf656bc4242f8bb5f9543bd9fae25",
            "a06dbb5f45584335bd5a7646fabe2e77",
            "9cda976d443141f88aafabb081763103"
          ]
        },
        "id": "Il5ZAAI9fRjC",
        "outputId": "30b664c9-ce62-4e64-d2f9-436a946e7b70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/512k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f9feb3d96db04c6ca0923588093276c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)_v2/resolve/main/special_tokens_map.json:   0%|          | 0.00/330 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bca62cf53ca542f7a95b569b68183361"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)3b_v2/resolve/main/tokenizer_config.json:   0%|          | 0.00/593 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8135648785d4766adb88a7fae7eb2da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)pen_llama_3b_v2/resolve/main/config.json:   0%|          | 0.00/506 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6ac5609a7954fdcbb35fd74cd796d90"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/6.85G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4e121e8d521b4ed99313532918af18c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)b_v2/resolve/main/generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d78f044db8fb44f8a374af4185ecb9ba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1468: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>Q: Create a detailed description for the following product: Corelogic Smooth Mouse, belonging to category: Optical Mouse\n",
            "A: The Corelogic Smooth Mouse is a wireless optical mouse that has a 1000 dpi resolution. It has a 2.4 GHz wireless connection and a 12-month warranty.\n",
            "Q: What is the price of the Corelogic Smooth Mouse?\n",
            "A: The Corelogic Smooth Mouse is priced at $29.99.\n",
            "Q: What is the weight of the Corelogic Smooth Mouse?\n",
            "A: The Corelogic Smooth Mouse weighs 0.1 pounds.\n",
            "Q: What is the dimensions of the Corelogic Smooth Mouse?\n",
            "A: The Corelogic Smooth Mouse has a dimension\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_modules = [\"q_proj\", \"v_proj\"]\n",
        "\n",
        "#If targeting all linear layers\n",
        "target_modules = ['q_proj','k_proj','v_proj','o_proj','gate_proj','down_proj','up_proj','lm_head']\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "r=16,\n",
        "target_modules = target_modules,\n",
        "lora_alpha=8,\n",
        "lora_dropout=0.05,\n",
        "bias=\"none\",\n",
        "task_type=\"CAUSAL_LM\")"
      ],
      "metadata": {
        "id": "MuaL5zKLgNdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_modules = str(model.modules)\n",
        "pattern = r'\\((\\w+)\\): Linear'\n",
        "linear_layer_names = re.findall(pattern, model_modules)\n",
        "\n",
        "names = []\n",
        "# Print the names of the Linear layers\n",
        "for name in linear_layer_names:\n",
        "    names.append(name)\n",
        "target_modules = list(set(names))"
      ],
      "metadata": {
        "id": "RfX6K_WeiBvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_dataset = rd_ds.get('test', rd_ds.get('validation', rd_ds['train']))"
      ],
      "metadata": {
        "id": "TSXwXSdWjVBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./output\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=64,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    save_total_limit=2,\n",
        ")"
      ],
      "metadata": {
        "id": "WBjj8Z6_jsIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#finetuning with LORA\n",
        "trainer = SFTTrainer(\n",
        "    model,\n",
        "    train_dataset=rd_ds['train'],\n",
        "    eval_dataset=eval_dataset,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=256,\n",
        "    args=training_args,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmOGOwFAiGyR",
        "outputId": "496f41fd-8532-4243-be91-d353c7c5f383"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using pad_token, but it is not set yet.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cuda runs out of memory with a small model llama-3b too. Unable to run Lora due to RAM constraints."
      ],
      "metadata": {
        "id": "dkQaJEa5Q32Z"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FP6HuX2-Q8pU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}