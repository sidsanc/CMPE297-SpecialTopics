{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZjIbspML7vAGw7S5hBcPD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sidsanc/CMPE297-SpecialTopics/blob/main/Assignment4/Mistral_Langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reference: [Article](https://medium.com/@scholarly360/mistral-7b-complete-guide-on-colab-129fa5e9a04d)"
      ],
      "metadata": {
        "id": "8N3X4sBs-E1j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBqbvbKeSpd4",
        "outputId": "09464703-d31e-4a30-aa9f-5f1aa2b3c81c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting CTransformers\n",
            "  Downloading ctransformers-0.2.27-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub (from CTransformers)\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: py-cpuinfo<10.0.0,>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from CTransformers) (9.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->CTransformers) (3.12.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->CTransformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->CTransformers) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->CTransformers) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->CTransformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->CTransformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->CTransformers) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->CTransformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->CTransformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->CTransformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->CTransformers) (2023.7.22)\n",
            "Installing collected packages: huggingface-hub, CTransformers\n",
            "Successfully installed CTransformers-0.2.27 huggingface-hub-0.18.0\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.0.320-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.22)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.6)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.1-py3-none-any.whl (27 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.43 (from langchain)\n",
            "  Downloading langsmith-0.0.49-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.1.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.6.1 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.320 langsmith-0.0.49 marshmallow-3.20.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install CTransformers\n",
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecKDp-5dOGUU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.llms import CTransformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeb8_wj7SfZh"
      },
      "outputs": [],
      "source": [
        "model_name = \"TheBloke/Mistral-7B-Instruct-v0.1-GGUF\"\n",
        "model_file = \"mistral-7b-instruct-v0.1.Q4_K_M.gguf\"\n",
        "\n",
        "config = {'max_new_tokens': 256, 'temperature': 0.5}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = CTransformers(model=model_name, model_file=model_file, config=config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "cff56d7846bb45a282f1bd857a39835a",
            "ecf9102c06e744f9a5bb554f69c54376",
            "78160f336e5a41ac936e3dca4169d2ce",
            "74455045569a4965844ad9538509f9ec",
            "c76371d189674c6688af218c8d0c8591",
            "64914909d78f4a59af48244d0c9f6696",
            "610bbe4a846741c3879ed79bc7cd46c1",
            "648614fdfda04a8ebac2c33c64b0ff3c",
            "4ce7d190cd0e4ae39b0f4eaa757fb4b8",
            "96112576b70e4d7baf12a0d255fb4e4c",
            "afdb74f322f1405abfe5cf4636778a03",
            "8b8891d1db2a47738feb643524edf856",
            "afd4b207ef4a4a3cb58279ad05259c20",
            "8b786ef54e81470fb3717f634512ca53",
            "66d530a188094051817dfd3009d5e9ed",
            "a2a52b76805b4d6db6e586d24ce692df",
            "a334dc97fea44da5bfb9b3f784095dba",
            "fac7633ee54b4b94a81a48254aaac1f4",
            "34bcee25ce224bcab72ca4ae1f568622",
            "a0440077bd584ac2913b30bd5c15d112",
            "202ee5ab378d47a293b1efc1b72e7112",
            "97063768120745e0b0c4ad768ad7472f",
            "00c5d3f563d14d698a7ff248556e27d1",
            "c5999e1efe9c4a41a5de51b172d9479d",
            "8a82190934d0459881ab8718b00c3366",
            "f8759763419b4f9bb70ce77fa4dda227",
            "d8b17e77864f4768acdd3e58747efef1",
            "8bbf6ad3429b4b768b758aa1a851a3bc",
            "148faae4dab84b6890e304f38b8d236e",
            "7904b8bcfd8f4eb99ef0e07ce57ea2a1",
            "3e36369942d54aa7bb33109a2e0ba192",
            "65acaec92a5c4c01818235f18cd26a1f",
            "14fd188ba45a43d8ac25ae3cab2642d5",
            "ed64a34e2fcd4460a54cd9a134a9fb2f",
            "1d74a7a6b30842a58d7b36b6360e9827",
            "205352dfea8d478d813436b258d78720",
            "77c4bb183c464f0aa359d2ae136b1d7d",
            "ff63fe696c0a4ca29dcce61e1aed2893",
            "4ddf6345477f4649ab1ec16b31a6e299",
            "2e8f66deec01491f8691b987673bfd19",
            "6d8cc836f1f6483a8d8ea26514224298",
            "e8a6f3e13dcb4dab8cb13e707ca3481b",
            "9656bbabf8b84acdaafb6fb9d2b0f5c4",
            "ad127aa1e20440ddafbe1021351d4e30"
          ]
        },
        "id": "v5SstqXxplW_",
        "outputId": "93d14d5f-422a-424f-b94e-44806fd7324a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cff56d7846bb45a282f1bd857a39835a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)a64a14aea61a4c468bbbf9f258a8/config.json:   0%|          | 0.00/31.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b8891d1db2a47738feb643524edf856"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "00c5d3f563d14d698a7ff248556e27d1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "mistral-7b-instruct-v0.1.Q4_K_M.gguf:   0%|          | 0.00/4.37G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed64a34e2fcd4460a54cd9a134a9fb2f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dtx9jhkOZAij",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "11181ed7-231c-4574-9af6-0369f992b82c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The date for the announcement was August 10th.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "template = \"\"\"<s>[INST] You are a helpful, respectful and honest assistant. Answer exactly in few words from the context\n",
        "Answer the question below from context below :\n",
        "{context}\n",
        "{question} [/INST] </s>\n",
        "\"\"\"\n",
        "question_p_1 = \"\"\"What is the date for announcement\"\"\"\n",
        "context_p_1 = \"\"\" On August 10 said that its arm JSW Neo Energy has agreed to buy a portfolio of 1753 mega watt renewable energy generation capacity from Mytrah Energy India Pvt Ltd for Rs 10,530 crore.\"\"\"\n",
        "prompt_1 = PromptTemplate(template=template, input_variables=[\"question\",\"context\"])\n",
        "\n",
        "llm_chain = LLMChain(prompt=prompt_1, llm=llm)\n",
        "response = llm_chain.run({\"question\":question_p_1,\"context\":context_p_1})\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2PX4ZbUctmJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "a13da19a-cad2-403b-cbee-58a97056df35"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Bonjour, comment allez-vous aujourd'hui ?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "template_2 = \"\"\"<s>[INST] Translate the following English text to French.\n",
        "English: {text} [/INST] </s>\"\"\"\n",
        "text_p_2 = \"\"\"Hello, how are you today?\"\"\"\n",
        "prompt_2 = PromptTemplate(template=template_2, input_variables=[\"text\"])\n",
        "\n",
        "llm_chain = LLMChain(prompt=prompt_2, llm=llm)\n",
        "response = llm_chain.run({\"text\":text_p_2})\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNiNsE1Ac-8n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "98343f09-2256-4ade-e446-f12366dec388"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" I don't have real-time information, but as of my last update, the President of the United States in 2023 would be Joe Biden. However, please check with a reliable source or search engine for the most accurate and up-to-date answer.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "template_3 = \"\"\"<s>[INST] Please answer the following question based on your knowledge.\n",
        "Question: {question} [/INST] </s>\"\"\"\n",
        "question_p_3 = \"\"\"Who is the President of the United States in 2023?\"\"\"\n",
        "prompt_3 = PromptTemplate(template=template_3, input_variables=[\"question\"])\n",
        "\n",
        "llm_chain = LLMChain(prompt=prompt_3, llm=llm)\n",
        "response = llm_chain.run({\"question\":question_p_3})\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NST7SGJsdHD8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "e0fc7c83-9d21-4685-f070-d9872e405a32"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" The error in the code is that the function `add_numbers` expects two arguments of type integer, but one of the arguments passed to the function is of type string. To fix this error, we need to convert the second argument (which is of type string) to an integer before adding it to the first argument. Here's the corrected code:\\n```python\\ndef add_numbers(a, b):\\n    return a + int(b)\\n\\nprint(add_numbers(10, '20'))\\n```\\nThe output of this code will be `30`, which is the correct result of adding 10 and 20.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "template_4 = \"\"\"<s>[INST] There is an error in the following Python code. Can you find and fix it?\n",
        "Code: {code} [/INST] </s>\"\"\"\n",
        "code_p_4 = \"\"\"def add_numbers(a, b):\n",
        "    return a + b\n",
        "\n",
        "print(add_numbers(10, '20'))\"\"\"\n",
        "prompt_4 = PromptTemplate(template=template_4, input_variables=[\"code\"])\n",
        "\n",
        "llm_chain = LLMChain(prompt=prompt_4, llm=llm)\n",
        "response = llm_chain.run({\"code\":code_p_4})\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PRjfsqneKzD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "d64291e7-5672-49fc-97c2-8968d3de59bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Once upon a time, there was a young woman named Lily who lived in a small apartment in the city. One day, she came home to find a mysterious box on her doorstep. The box had no return address or any indication of who it belonged to. It was wrapped in thick paper and secured with string, making her curious about what could be inside.\\n\\nLily cautiously lifted the lid of the box and gasped in amazement. Inside was an assortment of beautiful jewelry, clothes, and accessories that she had never seen before. The items were all exquisitely crafted and made from rare materials. She couldn't believe her luck at finding such treasure!\\n\\nBut as she examined the contents more closely, she noticed something strange. Each item was marked with a unique symbol that she had never seen before. She began to wonder if these symbols held some sort of secret meaning or power.\\n\\nDetermined to find out more, Lily set out to research the symbols. It wasn't long before she discovered that they were associated with an ancient civilization that had been lost to time. The items in the box were said to possess magical properties and could grant the owner great power and wealth.\\n\\nLily was both\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "template_5 = \"\"\"<s>[INST] Create a short story based on the following prompt.\n",
        "Prompt: {story_prompt} [/INST] </s>\"\"\"\n",
        "story_p_5 = \"\"\"A mysterious box arrives at your doorstep with no return address.\"\"\"\n",
        "prompt_5 = PromptTemplate(template=template_5, input_variables=[\"story_prompt\"])\n",
        "\n",
        "llm_chain = LLMChain(prompt=prompt_5, llm=llm)\n",
        "response = llm_chain.run({\"story_prompt\":story_p_5})\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_HKuo1Zm374"
      },
      "outputs": [],
      "source": []
    }
  ]
}